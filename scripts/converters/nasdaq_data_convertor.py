"""
Nasdaq Data Converter for LEAN
Converts Nasdaq ITCH format data (Trade and Quote) to QuantConnect LEAN format
"""

import argparse
import logging
import os
import re
import zipfile
from pathlib import Path

import pandas as pd

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def scan_files(data_dir, pattern="*.csv.zst"):
    """
    æ‰«ææŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶

    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„
        pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼

    Returns:
        list: æ–‡ä»¶Pathå¯¹è±¡åˆ—è¡¨
    """
    data_path = Path(data_dir)

    if not data_path.exists():
        logger.warning(f"Directory not found: {data_path}")
        return []

    files = list(data_path.glob(pattern))
    logger.info(f"Found {len(files)} files in {data_path}")

    return files


def parse_filename(filename, data_type):
    """
    è§£æžæ–‡ä»¶åæå–symbolå’Œæ—¥æœŸ

    Args:
        filename: æ–‡ä»¶å
        data_type: 'trade' or 'quote'

    Returns:
        dict: {'date': str, 'symbol': str} æˆ– None
    """
    if data_type == 'trade':
        # xnas-itch-20250827.trades.csv.zst (multi-symbol file)
        pattern = r"xnas-itch-(\d{8})\.trades\.csv\.zst$"
        match = re.match(pattern, filename)
        if match:
            return {'date': match.group(1), 'symbol': 'multi'}

    elif data_type == 'quote':
        # xnas-itch-20250827.mbp-1.AAPL.csv.zst (single-symbol file)
        pattern = r"xnas-itch-(\d{8})\.mbp-1\.(.+)\.csv\.zst$"
        match = re.match(pattern, filename)
        if match:
            return {'date': match.group(1), 'symbol': match.group(2)}

    logger.warning(f"Cannot parse filename: {filename}")
    return None


def convert_trade_tick(src_file, dst_root, target_symbol=None):
    """
    è½¬æ¢Trade Tickæ•°æ®åˆ°LEANæ ¼å¼

    Args:
        src_file: æºæ–‡ä»¶è·¯å¾„
        dst_root: è¾“å‡ºæ ¹ç›®å½•
        target_symbol: ç›®æ ‡symbol (Noneè¡¨ç¤ºå¤„ç†æ‰€æœ‰)
    """
    logger.info(f"Processing Trade file: {src_file.name}")

    # è¯»å–æ•°æ®
    df = pd.read_csv(src_file, compression="zstd")

    # ç­›é€‰symbol
    if target_symbol and target_symbol.upper() != 'ALL':
        df = df[df['symbol'] == target_symbol.upper()]
        if df.empty:
            logger.warning(f"No data found for symbol {target_symbol}")
            return

    # æŒ‰symbolåˆ†ç»„å¤„ç†
    for symbol, g in df.groupby("symbol"):
        logger.info(f"  Processing symbol: {symbol}")

        # ç›®æ ‡ç›®å½•
        dst_dir = Path(dst_root) / symbol.lower()
        dst_dir.mkdir(parents=True, exist_ok=True)

        # æ—¥æœŸ
        date_str = pd.to_datetime(g["ts_event"].iloc[0]).strftime("%Y%m%d")

        # LEANæ–‡ä»¶å
        zip_filename = f"{date_str}_trade.zip"
        csv_filename = f"{date_str}_{symbol.lower()}_Trade_Tick.csv"
        zip_path = dst_dir / zip_filename

        # æ—¶é—´è½¬æ¢ - ä¿æŒUTCæ—¶åŒºå¹¶è®¡ç®—ä»Žåˆå¤œå¼€å§‹çš„æ¯«ç§’æ•°
        timestamps = pd.to_datetime(g["ts_event"])
        if timestamps.dt.tz is None:
            timestamps = timestamps.dt.tz_localize('UTC')
        else:
            timestamps = timestamps.dt.tz_convert('UTC')

        midnight = timestamps.dt.normalize()
        time_ms = ((timestamps - midnight).dt.total_seconds() * 1000).astype(int)

        # æž„å»ºLEAN Trade Tickæ ¼å¼
        # Format: Time,TradeSale,Trade Volume,Exchange,Trade Sale Condition,Suspicious
        out_df = pd.DataFrame({
            "col1": time_ms,
            "col2": (g["price"] * 10000).astype(int),  # price in deci-cents
            "col3": g["size"].astype(int),
            "col4": "T",  # NASDAQ
            "col5": "0",  # No condition
            "col6": "0"   # Not suspicious
        })

        # å†™å…¥zip
        with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
            with zf.open(csv_filename, "w") as f:
                out_df.to_csv(f, index=False, header=False)

        logger.info(f"  âœ… Created: {zip_path} ({len(out_df)} ticks)")


def convert_quote_tick(src_file, dst_root, target_symbol=None):
    """
    è½¬æ¢Quote Tickæ•°æ®åˆ°LEANæ ¼å¼

    Args:
        src_file: æºæ–‡ä»¶è·¯å¾„
        dst_root: è¾“å‡ºæ ¹ç›®å½•
        target_symbol: ç›®æ ‡symbol (Noneè¡¨ç¤ºå¤„ç†æ‰€æœ‰)
    """
    logger.info(f"Processing Quote file: {src_file.name}")

    # è§£æžæ–‡ä»¶åèŽ·å–symbol
    metadata = parse_filename(src_file.name, 'quote')
    if not metadata:
        logger.error(f"Cannot parse quote filename: {src_file.name}")
        return

    symbol = metadata['symbol']
    date_str = metadata['date']

    # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡symbol
    if target_symbol and target_symbol.upper() != 'ALL':
        if symbol.upper() != target_symbol.upper():
            logger.info(f"  Skipping {symbol} (not target symbol)")
            return

    logger.info(f"  Processing symbol: {symbol}")

    # è¯»å–æ•°æ®
    df = pd.read_csv(src_file, compression="zstd")

    # æ£€æŸ¥å¿…éœ€åˆ—
    required_cols = ['ts_event', 'bid_px_00', 'ask_px_00', 'bid_sz_00', 'ask_sz_00']
    if not all(col in df.columns for col in required_cols):
        logger.error(f"Missing required columns in {src_file.name}")
        return

    # æ•°æ®æ¸…æ´— - åªä¿ç•™æœ‰æ•ˆçš„æŠ¥ä»·
    df = df[
        (df['bid_px_00'] > 0) &
        (df['ask_px_00'] > 0) &
        (df['bid_sz_00'] > 0) &
        (df['ask_sz_00'] > 0) &
        (df['bid_px_00'] < df['ask_px_00'])
    ].copy()

    if df.empty:
        logger.warning(f"No valid quotes found in {src_file.name}")
        return

    # åŽ»é‡ - åªä¿ç•™æŠ¥ä»·å˜åŒ–
    df['quote_key'] = (
        df['bid_px_00'].astype(str) + '_' +
        df['bid_sz_00'].astype(str) + '_' +
        df['ask_px_00'].astype(str) + '_' +
        df['ask_sz_00'].astype(str)
    )
    df = df.drop_duplicates(subset=['quote_key'], keep='first')
    df = df.drop(columns=['quote_key'])

    # æ—¶é—´è½¬æ¢
    timestamps = pd.to_datetime(df["ts_event"])
    if timestamps.dt.tz is None:
        timestamps = timestamps.dt.tz_localize('UTC')
    else:
        timestamps = timestamps.dt.tz_convert('UTC')

    midnight = timestamps.dt.normalize()
    time_ms = ((timestamps - midnight).dt.total_seconds() * 1000).astype(int)

    # æž„å»ºLEAN Quote Tickæ ¼å¼
    # Format: Time,Bid Sale,Bid Size,Ask Sale,Ask Size,Exchange,Quote Sale Condition,Suspicious
    out_df = pd.DataFrame({
        "col1": time_ms,
        "col2": (df["bid_px_00"] * 10000).astype(int),  # bid price in deci-cents
        "col3": df["bid_sz_00"].astype(int),
        "col4": (df["ask_px_00"] * 10000).astype(int),  # ask price in deci-cents
        "col5": df["ask_sz_00"].astype(int),
        "col6": "T",  # NASDAQ
        "col7": "0",  # No condition
        "col8": "0"   # Not suspicious
    })

    # ç›®æ ‡ç›®å½•
    dst_dir = Path(dst_root) / symbol.lower()
    dst_dir.mkdir(parents=True, exist_ok=True)

    # LEANæ–‡ä»¶å
    zip_filename = f"{date_str}_quote.zip"
    csv_filename = f"{date_str}_{symbol.lower()}_Quote_Tick.csv"
    zip_path = dst_dir / zip_filename

    # å†™å…¥zip
    with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        with zf.open(csv_filename, "w") as f:
            out_df.to_csv(f, index=False, header=False)

    logger.info(f"  âœ… Created: {zip_path} ({len(out_df)} ticks)")


def main_convert(trade_dir=None, quote_dir=None, output_dir=None, data_type='all', symbol='all'):
    """
    Main conversion function (can be called from other scripts)

    Args:
        trade_dir: Trade data directory
        quote_dir: Quote data directory
        output_dir: Output directory for LEAN data
        data_type: Type of data to convert ('trade', 'quote', or 'all')
        symbol: Symbol to convert (or 'all')
    """
    # Use defaults if not provided
    if trade_dir is None:
        trade_dir = "raw_data/us_trade_tick"
    if quote_dir is None:
        quote_dir = "raw_data/us_mbp_tick"
    if output_dir is None:
        output_dir = "Data/equity/usa/tick"

    logger.info("=" * 60)
    logger.info("Nasdaq Data Converter for LEAN")
    logger.info("=" * 60)
    logger.info(f"Type: {data_type}")
    logger.info(f"Symbol: {symbol}")
    logger.info("=" * 60)

    # è½¬æ¢Tradeæ•°æ®
    if data_type in ['trade', 'all']:
        logger.info("\nðŸ“Š Converting Trade Tick Data...")
        trade_files = scan_files(trade_dir, "*.csv.zst")

        for file in trade_files:
            convert_trade_tick(
                file,
                output_dir,
                target_symbol=symbol
            )

    # è½¬æ¢Quoteæ•°æ®
    if data_type in ['quote', 'all']:
        logger.info("\nðŸ“ˆ Converting Quote Tick Data...")
        quote_files = scan_files(quote_dir, "*.csv.zst")

        for file in quote_files:
            convert_quote_tick(
                file,
                output_dir,
                target_symbol=symbol
            )

    logger.info("\n" + "=" * 60)
    logger.info("âœ… Conversion Complete!")
    logger.info("=" * 60)


def main():
    """
    ä¸»å‡½æ•° (å‘½ä»¤è¡Œå…¥å£)
    """
    parser = argparse.ArgumentParser(
        description='Convert Nasdaq ITCH data to LEAN format',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Convert all trade data for all symbols
  python nasdaq_data_convertor.py --type trade

  # Convert all quote data for AAPL only
  python nasdaq_data_convertor.py --type quote --symbol AAPL

  # Convert both trade and quote for TSLA
  python nasdaq_data_convertor.py --type all --symbol TSLA

  # Convert everything (default)
  python nasdaq_data_convertor.py
        """
    )

    parser.add_argument(
        '--type',
        choices=['trade', 'quote', 'all'],
        default='all',
        help='Data type to convert (default: all)'
    )

    parser.add_argument(
        '--symbol',
        default='all',
        help='Symbol to convert (e.g., AAPL, TSLA, or all for all symbols, default: all)'
    )

    args = parser.parse_args()

    # Call main conversion function
    main_convert(
        data_type=args.type,
        symbol=args.symbol
    )


if __name__ == "__main__":
    main()
